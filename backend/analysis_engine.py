# æ–‡ä»¶å: backend/analysis_engine.py

import cv2
import time
import numpy as np
from collections import defaultdict, deque
import os
import shutil
import random
import matplotlib

matplotlib.use('Agg')
import matplotlib.pyplot as plt
from matplotlib.font_manager import FontProperties

from ultralytics import YOLO

# å…¨å±€æ¨¡å‹å®ä¾‹ï¼Œé¿å…é‡å¤åŠ è½½
_pose_model = None

def get_pose_model():
    """è·å–æˆ–åˆå§‹åŒ–YOLOå§¿æ€æ£€æµ‹æ¨¡å‹"""
    global _pose_model
    if _pose_model is None:
        try:
            _pose_model = YOLO('yolov8n-pose.pt')
            print("YOLOv8å§¿æ€æ£€æµ‹æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"åŠ è½½YOLOv8æ¨¡å‹å¤±è´¥: {e}")
            raise
    return _pose_model


def analyze_witmotion_segment(segment: dict) -> dict:
    """
    ä¸º Witmotion åˆ†æ®µæ•°æ®æä¾›ä¸€ä¸ªè½»é‡è¯„åˆ†å‡½æ•°ï¼Œè¿”å› {action_type, score, features}ã€‚
    è¯¥å‡½æ•°ä¸ä¼šä¾èµ–é‡æ¨¡å‹ï¼Œæ–¹ä¾¿åœ¨åç«¯å¯åŠ¨æ—¶è¢«å¯¼å…¥è°ƒç”¨ã€‚
    """
    try:
        features = segment.get('features', {})
        asx = float(features.get('AsX_mean', 0))
        asy = float(features.get('AsY_mean', 0))
        asz = float(features.get('AsZ_mean', 0))
        qvar = float(features.get('Q_var', 0))
        hx = float(features.get('HX_mean', 0))
        hy = float(features.get('HY_mean', 0))
        hz = float(features.get('HZ_mean', 0))

        activity = (abs(asx) + abs(asy) + abs(asz)) / 3.0
        activity_score = max(0.0, min(40.0, activity * 0.6))

        q_score = max(0.0, min(30.0, qvar * 100.0))

        mag_variation = abs(hx) + abs(hy) + abs(hz)
        mag_score = max(0.0, min(20.0, 20.0 - (mag_variation * 0.05)))

        action_type = segment.get('action_type', '')
        match_bonus = 0.0
        if 'å‡†å¤‡' in action_type and activity < 5:
            match_bonus = 5.0
        if ('è¿›æ”»' in action_type or 'åˆº' in action_type) and activity > 15:
            match_bonus = 10.0

        total = activity_score + q_score + mag_score + match_bonus
        total = max(0.0, min(100.0, total))

        return {
            'action_type': str(action_type),
            'score': float(round(total, 1)),
            'features': {
                'AsX_mean': asx,
                'AsY_mean': asy,
                'AsZ_mean': asz,
                'Q_var': qvar,
                'HX_mean': hx,
                'HY_mean': hy,
                'HZ_mean': hz
            }
        }
    except Exception as e:
        print(f"analyze_witmotion_segment å‡ºé”™: {e}")
        return {'action_type': segment.get('action_type', 'unknown'), 'score': 0.0, 'features': segment.get('features', {})}

def analyze_single_frame(frame):
    """
    åˆ†æå•å¸§å›¾åƒï¼Œè¿”å›å…³é”®ç‚¹å’Œè¯„åˆ†

    Args:
        frame: OpenCVæ ¼å¼çš„å›¾åƒå¸§

    Returns:
        dict: åŒ…å«å…³é”®ç‚¹åæ ‡ã€ç½®ä¿¡åº¦å’ŒåŠ¨ä½œè¯„åˆ†
    """
    try:
        model = get_pose_model()

        # æ‰§è¡Œå§¿æ€æ£€æµ‹
        results = model(frame, verbose=False)

        if not results or len(results) == 0:
            return {
                "success": False,
                "message": "æœªæ£€æµ‹åˆ°äººä½“"
            }

        result = results[0]

        # æå–å…³é”®ç‚¹æ•°æ®
        if result.keypoints is None or result.keypoints.xy.shape[1] == 0:
            return {
                "success": False,
                "message": "æœªæ£€æµ‹åˆ°å…³é”®ç‚¹"
            }

        keypoints_xy = result.keypoints.xy[0].cpu().numpy()  # å…³é”®ç‚¹åæ ‡ (17, 2)
        keypoints_conf = result.keypoints.conf[0].cpu().numpy() if result.keypoints.conf is not None else None  # ç½®ä¿¡åº¦ (17,)

        # æ„å»ºå…³é”®ç‚¹æ•°æ®
        keypoints_data = []
        keypoint_names = [
            "é¼»å­", "å·¦çœ¼", "å³çœ¼", "å·¦è€³", "å³è€³",
            "å·¦è‚©", "å³è‚©", "å·¦è‚˜", "å³è‚˜", "å·¦è…•", "å³è…•",
            "å·¦é«‹", "å³é«‹", "å·¦è†", "å³è†", "å·¦è¸", "å³è¸"
        ]

        for i, (x, y) in enumerate(keypoints_xy):
            conf = float(keypoints_conf[i]) if keypoints_conf is not None else 1.0
            keypoints_data.append({
                "name": keypoint_names[i] if i < len(keypoint_names) else f"Point{i}",
                "x": float(x),
                "y": float(y),
                "confidence": float(conf),  # ç¡®ä¿æ˜¯Python float
                "detected": bool(conf > 0.5)  # ç¡®ä¿æ˜¯Python bool
            })

        # è®¡ç®—ç®€å•çš„å§¿æ€è¯„åˆ†
        score = calculate_realtime_score(keypoints_xy, keypoints_conf)

        # æ£€æµ‹å½“å‰åŠ¨ä½œç±»å‹
        action_type = detect_action_type(keypoints_xy)

        # è®¡ç®—å§¿æ€æŒ‡æ ‡
        posture_metrics = calculate_posture_metrics(keypoints_xy)

        # ç¡®ä¿æ‰€æœ‰æ•°å€¼éƒ½æ˜¯PythonåŸç”Ÿç±»å‹ï¼ˆå¯JSONåºåˆ—åŒ–ï¼‰
        return {
            "success": True,
            "keypoints": keypoints_data,
            "score": float(score),  # è½¬æ¢ä¸ºPython float
            "action_type": str(action_type),  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²
            "person_detected": True,
            "posture_metrics": {k: float(v) for k, v in posture_metrics.items()}  # è½¬æ¢æ‰€æœ‰å€¼ä¸ºPython float
        }

    except Exception as e:
        print(f"åˆ†æå¸§æ—¶å‡ºé”™: {e}")
        return {
            "success": False,
            "message": str(e)
        }

def calculate_realtime_score(keypoints, confidences):
    """
    è®¡ç®—å®æ—¶å§¿æ€è¯„åˆ† (0-100)

    ä¸“ä¸šå‡»å‰‘è¯„åˆ†æ ‡å‡†ï¼š
    - å…³é”®ç‚¹æ£€æµ‹è´¨é‡ï¼š20åˆ†
    - èº«ä½“å¹³è¡¡ä¸å§¿æ€ï¼š25åˆ†
    - æ‰‹è‡‚ä¼¸å±•ä¸å‰‘å°–æ§åˆ¶ï¼š25åˆ†
    - è…¿éƒ¨å§¿æ€ä¸å¼“æ­¥è´¨é‡ï¼š20åˆ†
    - æ•´ä½“åè°ƒæ€§ï¼š10åˆ†
    """
    try:
        score = 0.0
        details = {}  # å­˜å‚¨è¯¦ç»†è¯„åˆ†ä¿¡æ¯

        # 1. å…³é”®ç‚¹æ£€æµ‹å®Œæ•´æ€§ (20åˆ†)
        if confidences is not None:
            valid_points = np.sum(confidences > 0.5)
            total_points = len(confidences)
            detection_rate = valid_points / total_points
            avg_confidence = np.mean(confidences[confidences > 0.5]) if valid_points > 0 else 0
            detection_score = detection_rate * avg_confidence * 20
            score += detection_score
            details['detection'] = round(detection_score, 1)

        # 2. èº«ä½“å¹³è¡¡ä¸å§¿æ€ (25åˆ†)
        balance_score = 0.0

        # 2.1 è‚©éƒ¨æ°´å¹³åº¦ (8åˆ†)
        left_shoulder, right_shoulder = keypoints[5], keypoints[6]
        if not np.isnan(left_shoulder).any() and not np.isnan(right_shoulder).any():
            shoulder_diff = abs(left_shoulder[1] - right_shoulder[1])
            shoulder_distance = np.linalg.norm(left_shoulder - right_shoulder)
            if shoulder_distance > 0:
                shoulder_balance = 1 - min(shoulder_diff / shoulder_distance, 1.0)
                balance_score += shoulder_balance * 8

        # 2.2 é«‹éƒ¨ç¨³å®šæ€§ (8åˆ†)
        left_hip, right_hip = keypoints[11], keypoints[12]
        if not np.isnan(left_hip).any() and not np.isnan(right_hip).any():
            hip_diff = abs(left_hip[1] - right_hip[1])
            hip_distance = np.linalg.norm(left_hip - right_hip)
            if hip_distance > 0:
                hip_balance = 1 - min(hip_diff / hip_distance, 1.0)
                balance_score += hip_balance * 8

        # 2.3 èº¯å¹²ç›´ç«‹åº¦ (9åˆ†)
        nose, left_hip = keypoints[0], keypoints[11]
        if not np.isnan(nose).any() and not np.isnan(left_hip).any():
            vertical_diff = abs(nose[0] - left_hip[0])
            torso_height = abs(nose[1] - left_hip[1])
            if torso_height > 0:
                torso_straightness = 1 - min(vertical_diff / torso_height, 1.0)
                balance_score += torso_straightness * 9

        score += balance_score
        details['balance'] = round(balance_score, 1)

        # 3. æ‰‹è‡‚ä¼¸å±•ä¸å‰‘å°–æ§åˆ¶ (25åˆ†)
        arm_score = 0.0

        # 3.1 å³è‡‚ä¼¸å±•åº¦ (15åˆ†) - å‡»å‰‘ä¸»è¦ç”¨å³æ‰‹
        right_shoulder, right_elbow, right_wrist = keypoints[6], keypoints[8], keypoints[10]
        arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)
        if arm_angle is not None:
            # æ ‡å‡†å‡»å‰‘å‡ºå‡»å§¿æ€ï¼šæ‰‹è‡‚è§’åº¦åº”åœ¨160-180åº¦ä¹‹é—´
            if arm_angle >= 160:
                arm_extension = ((arm_angle - 160) / 20) * 15
            else:
                arm_extension = (arm_angle / 160) * 10
            arm_score += min(arm_extension, 15)

        # 3.2 æ‰‹è‡‚é«˜åº¦æ§åˆ¶ (10åˆ†)
        if not np.isnan(right_wrist).any() and not np.isnan(right_shoulder).any():
            wrist_height_diff = abs(right_wrist[1] - right_shoulder[1])
            ideal_height = np.linalg.norm(right_shoulder - right_wrist) * 0.3
            if ideal_height > 0:
                height_control = 1 - min(wrist_height_diff / ideal_height, 1.0)
                arm_score += height_control * 10

        score += arm_score
        details['arm'] = round(arm_score, 1)

        # 4. è…¿éƒ¨å§¿æ€ä¸å¼“æ­¥è´¨é‡ (20åˆ†)
        leg_score = 0.0

        # 4.1 å³è†è§’åº¦ (å‰è…¿å¼“æ­¥) (10åˆ†)
        right_hip, right_knee, right_ankle = keypoints[12], keypoints[14], keypoints[16]
        right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)
        if right_knee_angle is not None:
            # æ ‡å‡†å¼“æ­¥ï¼šå‰è†è§’åº¦åº”åœ¨90-120åº¦
            if 90 <= right_knee_angle <= 120:
                knee_quality = 10
            elif right_knee_angle < 90:
                knee_quality = (right_knee_angle / 90) * 10
            else:
                knee_quality = max(0, 10 - (right_knee_angle - 120) / 6)
            leg_score += knee_quality

        # 4.2 åè…¿ä¼¸å±•åº¦ (10åˆ†)
        left_hip, left_knee, left_ankle = keypoints[11], keypoints[13], keypoints[15]
        left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle)
        if left_knee_angle is not None:
            # åè…¿åº”å°½é‡ä¼¸ç›´ (æ¥è¿‘180åº¦)
            back_leg_extension = (left_knee_angle / 180) * 10
            leg_score += back_leg_extension

        score += leg_score
        details['leg'] = round(leg_score, 1)

        # 5. æ•´ä½“åè°ƒæ€§ (10åˆ†)
        coordination_score = 0.0

        # æ£€æŸ¥æ‰€æœ‰å…³é”®éƒ¨ä½æ˜¯å¦éƒ½æ£€æµ‹åˆ°
        key_parts = [0, 5, 6, 8, 10, 11, 12, 14, 16]  # é¼»ã€è‚©ã€è‚˜ã€è…•ã€é«‹ã€è†ã€è¸
        detected_parts = sum(1 for i in key_parts if confidences[i] > 0.5) if confidences is not None else 0
        coordination_score = (detected_parts / len(key_parts)) * 10

        score += coordination_score
        details['coordination'] = round(coordination_score, 1)

        # æœ€ç»ˆè¯„åˆ†
        final_score = round(min(100, max(0, score)), 1)

        # è¾“å‡ºè¯¦ç»†è¯„åˆ†ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        print(f"å®æ—¶è¯„åˆ†è¯¦æƒ… - æ€»åˆ†:{final_score} | æ£€æµ‹:{details.get('detection',0)} | "
              f"å¹³è¡¡:{details.get('balance',0)} | æ‰‹è‡‚:{details.get('arm',0)} | "
              f"è…¿éƒ¨:{details.get('leg',0)} | åè°ƒ:{details.get('coordination',0)}")

        return final_score

    except Exception as e:
        print(f"è®¡ç®—è¯„åˆ†æ—¶å‡ºé”™: {e}")
        return 50.0

def calculate_posture_metrics(keypoints):
    """
    è®¡ç®—è¯¦ç»†çš„å§¿æ€æŒ‡æ ‡

    è¿”å›å„é¡¹å§¿æ€æŒ‡æ ‡çš„å…·ä½“æ•°å€¼
    """
    try:
        metrics = {}

        # 1. å¤´éƒ¨ä½ç½® - åŸºäºé¼»å­å’Œé«‹éƒ¨ä¸­å¿ƒ
        nose = keypoints[0]
        left_hip, right_hip = keypoints[11], keypoints[12]
        if not any(np.isnan(p).any() for p in [nose, left_hip, right_hip]):
            hip_center = (left_hip + right_hip) / 2
            head_alignment = float(abs(nose[0] - hip_center[0]))
            torso_height = float(abs(nose[1] - hip_center[1]))
            if torso_height > 0:
                head_score = max(0, 100 - (head_alignment / torso_height) * 100)
                metrics['å¤´éƒ¨ä½ç½®'] = float(round(head_score, 1))
            else:
                metrics['å¤´éƒ¨ä½ç½®'] = 50.0
        else:
            metrics['å¤´éƒ¨ä½ç½®'] = 0.0

        # 2. è‚©éƒ¨æ°´å¹³
        left_shoulder, right_shoulder = keypoints[5], keypoints[6]
        if not any(np.isnan(p).any() for p in [left_shoulder, right_shoulder]):
            shoulder_diff = float(abs(left_shoulder[1] - right_shoulder[1]))
            shoulder_distance = float(np.linalg.norm(left_shoulder - right_shoulder))
            if shoulder_distance > 0:
                shoulder_score = max(0, 100 - (shoulder_diff / shoulder_distance) * 200)
                metrics['è‚©éƒ¨æ°´å¹³'] = float(round(shoulder_score, 1))
            else:
                metrics['è‚©éƒ¨æ°´å¹³'] = 50.0
        else:
            metrics['è‚©éƒ¨æ°´å¹³'] = 0.0

        # 3. æ‰‹è‡‚è§’åº¦
        right_shoulder, right_elbow, right_wrist = keypoints[6], keypoints[8], keypoints[10]
        arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist)
        if arm_angle is not None:
            # æ‰‹è‡‚è§’åº¦æ¥è¿‘180åº¦è¶Šå¥½
            metrics['æ‰‹è‡‚è§’åº¦'] = float(round((float(arm_angle) / 180) * 100, 1))
        else:
            metrics['æ‰‹è‡‚è§’åº¦'] = 0.0

        # 4. è…¿éƒ¨å§¿æ€ - å‰è…¿å¼“æ­¥è´¨é‡
        right_hip, right_knee, right_ankle = keypoints[12], keypoints[14], keypoints[16]
        right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle)
        if right_knee_angle is not None:
            right_knee_angle = float(right_knee_angle)
            # æ ‡å‡†å¼“æ­¥è§’åº¦åœ¨90-120åº¦
            if 90 <= right_knee_angle <= 120:
                leg_score = 100.0
            elif right_knee_angle < 90:
                leg_score = (right_knee_angle / 90) * 100
            else:
                leg_score = max(0, 100 - (right_knee_angle - 120) / 0.6)
            metrics['è…¿éƒ¨å§¿æ€'] = float(round(leg_score, 1))
        else:
            metrics['è…¿éƒ¨å§¿æ€'] = 0.0

        # 5. æ•´ä½“å¹³è¡¡
        if not any(np.isnan(p).any() for p in [left_hip, right_hip, left_shoulder, right_shoulder]):
            hip_diff = float(abs(left_hip[1] - right_hip[1]))
            shoulder_diff = float(abs(left_shoulder[1] - right_shoulder[1]))
            avg_diff = (hip_diff + shoulder_diff) / 2
            hip_shoulder_distance = float(np.linalg.norm(left_hip - left_shoulder))
            if hip_shoulder_distance > 0:
                balance_score = max(0, 100 - (avg_diff / hip_shoulder_distance) * 200)
                metrics['æ•´ä½“å¹³è¡¡'] = float(round(balance_score, 1))
            else:
                metrics['æ•´ä½“å¹³è¡¡'] = 50.0
        else:
            metrics['æ•´ä½“å¹³è¡¡'] = 0.0

        return metrics

    except Exception as e:
        print(f"è®¡ç®—å§¿æ€æŒ‡æ ‡å‡ºé”™: {e}")
        return {
            'å¤´éƒ¨ä½ç½®': 0.0,
            'è‚©éƒ¨æ°´å¹³': 0.0,
            'æ‰‹è‡‚è§’åº¦': 0.0,
            'è…¿éƒ¨å§¿æ€': 0.0,
            'æ•´ä½“å¹³è¡¡': 0.0
        }

def detect_action_type(keypoints):
    """
    æ£€æµ‹å½“å‰å‡»å‰‘åŠ¨ä½œç±»å‹

    åŸºäºå§¿æ€å…³é”®ç‚¹åˆ†æè¯†åˆ«ä»¥ä¸‹åŠ¨ä½œï¼š
    - è¿›æ”»ç›´åˆºï¼šæ‰‹è‡‚ä¼¸å±• + å‰è…¿å¼¯æ›² + é‡å¿ƒå‰ç§»
    - å‡†å¤‡å§¿åŠ¿ï¼šæ ‡å‡†å‡»å‰‘ç«™å§¿
    - é˜²å®ˆåæ’¤ï¼šé‡å¿ƒåç§»
    - æ ¼æŒ¡å§¿åŠ¿ï¼šæ‰‹è‡‚æŠ¬èµ·
    """
    try:
        # æå–å…³é”®ç‚¹
        nose = keypoints[0]
        right_shoulder, right_elbow, right_wrist = keypoints[6], keypoints[8], keypoints[10]
        left_hip, right_hip = keypoints[11], keypoints[12]
        left_knee, right_knee = keypoints[13], keypoints[14]
        left_ankle, right_ankle = keypoints[15], keypoints[16]

        # æ£€æŸ¥å…³é”®ç‚¹æœ‰æ•ˆæ€§
        if any(np.isnan(p).any() for p in [right_shoulder, right_wrist, right_hip]):
            return "å§¿æ€è¯†åˆ«ä¸­..."

        # 1. è®¡ç®—æ‰‹è‡‚ä¼¸å±•åº¦
        arm_extension = np.linalg.norm(right_wrist - right_shoulder)
        arm_angle = calculate_angle(right_shoulder, right_elbow, right_wrist) if not np.isnan(right_elbow).any() else None

        # 2. è®¡ç®—è…¿éƒ¨å§¿æ€
        right_knee_angle = calculate_angle(right_hip, right_knee, right_ankle) \
            if not any(np.isnan(p).any() for p in [right_knee, right_ankle]) else None
        left_knee_angle = calculate_angle(left_hip, left_knee, left_ankle) \
            if not any(np.isnan(p).any() for p in [left_hip, left_knee, left_ankle]) else None

        # 3. è®¡ç®—é‡å¿ƒä½ç½® (é¼»å­ç›¸å¯¹äºé«‹éƒ¨ä¸­å¿ƒçš„ä½ç½®)
        hip_center = (left_hip + right_hip) / 2
        forward_lean = nose[0] - hip_center[0]  # æ­£å€¼è¡¨ç¤ºå‰å€¾ï¼Œè´Ÿå€¼è¡¨ç¤ºåå€¾

        # åŠ¨ä½œè¯†åˆ«é€»è¾‘
        # è¿›æ”»ç›´åˆºï¼šæ‰‹è‡‚ä¼¸å±• + å‰è†å¼¯æ›² + é‡å¿ƒå‰ç§»
        if arm_angle and arm_angle > 160 and arm_extension > 120:
            if right_knee_angle and 80 <= right_knee_angle <= 130 and forward_lean > 20:
                return "ğŸ—¡ï¸ è¿›æ”»ç›´åˆº"
            else:
                return "ğŸ¯ å‡†å¤‡å‡ºå‡»"

        # é˜²å®ˆåæ’¤ï¼šé‡å¿ƒåç§»
        if forward_lean < -30:
            return "ğŸ›¡ï¸ é˜²å®ˆåæ’¤"

        # æ ¼æŒ¡å§¿åŠ¿ï¼šæ‰‹è…•é«˜äºè‚©è†€
        if right_wrist[1] < right_shoulder[1] - 30:
            return "âš”ï¸ æ ¼æŒ¡å§¿åŠ¿"

        # å¼“æ­¥å§¿åŠ¿ï¼šå‰è…¿å¼¯æ›²ä½†æ‰‹è‡‚æœªä¼¸å±•
        if right_knee_angle and 80 <= right_knee_angle <= 130:
            if left_knee_angle and left_knee_angle > 160:
                return "ğŸ¹ å¼“æ­¥å§¿æ€"

        # æ ‡å‡†å‡†å¤‡å§¿åŠ¿
        if arm_extension < 120 and abs(forward_lean) < 30:
            return "âš¡ å‡†å¤‡å§¿åŠ¿"

        # ç§»åŠ¨ä¸­
        return "ğŸ­ åŠ¨æ€è°ƒæ•´"

    except Exception as e:
        print(f"åŠ¨ä½œè¯†åˆ«å‡ºé”™: {e}")
        return "æœªçŸ¥åŠ¨ä½œ"

def get_chinese_font():
    font_paths = [
        'C:/Windows/Fonts/msyh.ttc',  # å¾®è½¯é›…é»‘
        'C:/Windows/Fonts/simhei.ttf', # é»‘ä½“
        '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',
        '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc'
    ]
    for path in font_paths:
        if os.path.exists(path): return FontProperties(fname=path, size=12)
    print("è­¦å‘Š: æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼ŒæŠ¥å‘Šå›¾è¡¨å¯èƒ½æ˜¾ç¤ºä¸ºæ–¹æ¡†ã€‚")
    return None
chinese_font = get_chinese_font()

def calculate_angle(p1, p2, p3):
    if p1 is None or p2 is None or p3 is None or np.isnan(p1).any() or np.isnan(p2).any() or np.isnan(p3).any(): return None
    p1, p2, p3 = np.array(p1), np.array(p2), np.array(p3)
    radians = np.arctan2(p3[1]-p2[1], p3[0]-p2[0]) - np.arctan2(p1[1]-p2[1], p1[0]-p2[0])
    angle = np.abs(radians * 180.0 / np.pi)
    return 360 - angle if angle > 180.0 else angle

def calculate_action_score(metrics, video_width):
    base_score = 5.0
    if metrics.get("æœ€å¤§æ‰‹è‡‚ä¼¸å±•(Â°)") and "N/A" not in metrics["æœ€å¤§æ‰‹è‡‚ä¼¸å±•(Â°)"]:
        arm_angle = float(metrics["æœ€å¤§æ‰‹è‡‚ä¼¸å±•(Â°)"].replace('Â°', ''))
        if arm_angle > 170: base_score += 2.5
        elif arm_angle > 160: base_score += 1.5
    if metrics.get("å¼“æ­¥é€Ÿåº¦(åƒç´ /ç§’)"):
        lunge_speed = float(metrics["å¼“æ­¥é€Ÿåº¦(åƒç´ /ç§’)"])
        if lunge_speed > video_width * 0.2: base_score += 2.0
        elif lunge_speed > video_width * 0.15: base_score += 1.0
    return round(max(0, min(10.0, base_score)), 1)

def create_skeleton_video_yolo(input_video_path, output_video_path):
    try: model = YOLO('yolov8n-pose.pt')
    except Exception as e: print(f"é”™è¯¯ï¼šåŠ è½½YOLOv8æ¨¡å‹å¤±è´¥: {e}"); return False
    cap = cv2.VideoCapture(input_video_path)
    if not cap.isOpened(): print(f"é”™è¯¯: æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶ {input_video_path}"); return False
    w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS); fps = fps if fps and fps > 0 else 25
    fourcc = cv2.VideoWriter_fourcc(*'avc1'); writer = cv2.VideoWriter(output_video_path, fourcc, fps, (w, h))
    if not writer.isOpened(): print("é”™è¯¯: æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨ã€‚"); cap.release(); return False
    print("YOLOv8å§¿æ€ä¼°è®¡å¼€å§‹...")
    results_generator = model(input_video_path, stream=True, verbose=False)
    for r in results_generator:
        annotated_frame = r.plot()
        writer.write(annotated_frame)
    print(f"YOLOv8éª¨æ¶è§†é¢‘å·²ç”Ÿæˆ: {output_video_path}"); cap.release(); writer.release(); return True

def generate_chart_image(chart_type, data, output_path):
    plt.style.use('dark_background'); fig, ax = plt.subplots(figsize=(8, 6))
    font_props = {'fontproperties': chinese_font} if chinese_font else {}
    title_font_props = {**font_props, 'size': 16, 'color': 'white'}
    if chart_type == 'radar':
        labels, angles = data['labels'], np.linspace(0, 2*np.pi, len(data['labels']), endpoint=False).tolist()+[0]
        ax = plt.subplot(111, polar=True); ax.set_theta_offset(np.pi/2); ax.set_theta_direction(-1)
        plt.xticks(angles[:-1], labels, color="grey", **font_props)
        def plot_radar(v, c, l): ax.plot(angles, v+[v[0]], c=c, lw=2, label=l); ax.fill(angles, v+[v[0]], c=c, alpha=0.25)
        plot_radar(data['last_training'], '#FFBA57', 'ä¸Šæ¬¡è®­ç»ƒ'); plot_radar(data['this_training'], '#639AFF', 'æœ¬æ¬¡è®­ç»ƒ')
        legend = ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1));
        if chinese_font: [t.set_fontproperties(chinese_font) for t in legend.get_texts()]
        ax.set_title("æŠ€æœ¯æˆé•¿é›·è¾¾å›¾", y=1.1, **title_font_props)
    elif chart_type == 'line':
        ax.plot(data['categories'], data['last_day'], color='#FFBA57', label='æ˜¨å¤©'); ax.plot(data['categories'], data['today'], color='#639AFF', label='ä»Šå¤©')
        legend = ax.legend()
        if chinese_font: [t.set_fontproperties(chinese_font) for t in legend.get_texts()]
        ax.set_title("ç»¼åˆè¯„åˆ†è¶‹åŠ¿", **title_font_props); plt.xticks(rotation=30, **font_props); plt.yticks(**font_props)
    fig.tight_layout(); plt.savefig(output_path, transparent=True, bbox_inches='tight'); plt.close(fig)

def generate_html_report(data, output_dir):
    highlights = "".join([f"""<div class="highlight-card"><img src="{os.path.basename(item['image_path'])}"><div class="details"><p><strong>æ—¶é—´ç‚¹:</strong> {item['timestamp']} Â <span class="tag {'tag-good' if item['type']=='good' else 'tag-bad'}">{'äº®ç‚¹æ—¶åˆ»' if item['type']=='good' else 'å¾…æ”¹è¿›'}</span></p><p><strong>åˆ†æé¡¹:</strong> {item['title']}</p><p><strong>è¯´æ˜:</strong> {item['description']}</p></div></div>""" for item in data['highlights']])
    html = f"""<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><title>å‡»å‰‘è®­ç»ƒåˆ†ææŠ¥å‘Š</title><style>body{{font-family:sans-serif;margin:0;background-color:#0c0a15;color:#e5e7eb;}} .container{{max-width:900px;margin:20px auto;padding:20px;background-color:#111827;border-radius:12px;border:1px solid #374151;}} h1,h2,h3{{color:#fff;border-bottom:1px solid #374151;padding-bottom:10px;}} h1{{text-align:center;}} .highlight-card{{margin-bottom:25px;border:1px solid #374151;border-radius:8px;overflow:hidden;background-color:#1f2937;}} .highlight-card img{{max-width:100%;}} .highlight-card .details{{padding:15px;}} .tag{{display:inline-block;padding:4px 10px;border-radius:12px;font-size:12px;font-weight:bold;}} .tag-good{{background-color:#10B981;color:#fff;}} .tag-bad{{background-color:#EF4444;color:#fff;}} .chart-container{{text-align:center;margin-top:30px;}} .chart-container img{{max-width:90%;margin:10px auto;background-color:rgba(31,41,55,0.8);border-radius:8px;}}</style></head><body><div class="container"><h1>å‡»å‰‘è®­ç»ƒåˆ†ææŠ¥å‘Š</h1><h2>è®­ç»ƒæ—¥æœŸ: {data['date']}</h2><h3>å…³é”®æ—¶åˆ»åˆ†æ</h3>{highlights}<h3>æ•°æ®ç»Ÿè®¡</h3><div class="chart-container"><img src="radar_chart.png"><img src="line_chart.png"></div><h3>AIç»¼åˆè¯„è¯­</h3><div style="background-color:#1f2937;padding:15px;border-radius:5px;white-space:pre-wrap;">{data['ai_summary']}</div></div></body></html>"""
    with open(os.path.join(output_dir, "report.html"), "w", encoding="utf-8") as f: f.write(html)


def run_full_analysis(video_path: str, base_output_dir: str, session_id: str) -> dict:
    output_dir = os.path.join(base_output_dir, session_id); os.makedirs(output_dir, exist_ok=True)
    try: model = YOLO('yolov8n-pose.pt')
    except Exception as e: return {"error": f"åŠ è½½YOLOv8æ¨¡å‹å¤±è´¥: {e}"}
    
    print("YOLOv8åŸç”Ÿè§†é¢‘å¤„ç†å¼€å§‹...")
    results_generator = model(video_path, stream=True, verbose=False)
    cap = cv2.VideoCapture(video_path); w, h = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)); fps = cap.get(cv2.CAP_PROP_FPS); fps = fps if fps and fps > 0 else 25
    all_frame_keypoints = [{'frame_idx': i, 'keypoints': r.keypoints.xy[0].cpu().numpy() if r.keypoints and r.keypoints.xy.shape[1]>0 else None} for i, r in enumerate(results_generator)]
    print(f"YOLOv8å¤„ç†å®Œæˆï¼Œå…±åˆ†æ {len(all_frame_keypoints)} å¸§ã€‚")

    detected_actions = []; state = "IDLE"; action_buffer = []; keypoints_history = deque(maxlen=max(5, int(fps/5)));
    
    # â–¼â–¼â–¼ æ ¸å¿ƒç®—æ³•å‡çº§ï¼šè°ƒæ•´é˜ˆå€¼å’Œå¢åŠ æœ€å°æ—¶é•¿ â–¼â–¼â–¼
    # å°†é˜ˆå€¼ä»ç›¸å¯¹äºè§†é¢‘å®½åº¦(w)çš„æ¯”ä¾‹ï¼Œæ”¹ä¸ºä¸€ä¸ªæ›´é€šç”¨çš„ç»å¯¹å€¼
    # è¿™äº›å€¼æ˜¯åœ¨å‡è®¾è¿åŠ¨å‘˜åœ¨ç”»é¢ä¸­å æœ‰ä¸€å®šæ¯”ä¾‹çš„æƒ…å†µä¸‹è®¾å®šçš„ï¼Œæ›´å…·æ™®é€‚æ€§
    VEL_START = 10.0     # é™ä½å¯åŠ¨é€Ÿåº¦é˜ˆå€¼ï¼Œä½¿å…¶æ›´çµæ•
    VEL_END = 100.0       # é™ä½ç»“æŸé€Ÿåº¦é˜ˆå€¼
    MIN_ACTION_DURATION = 0.01 # åŠ¨ä½œçš„æœ€çŸ­æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œè¿‡æ»¤æ‰æ— æ•ˆçš„æŠ–åŠ¨
    # â–²â–²â–² å‡çº§ç»“æŸ â–²â–²â–²

    idle_frame_counter = 0
    IDLE_CONFIRMATION_FRAMES = max(3, int(fps / 5))

    for data in all_frame_keypoints:
        keypoints_history.append(data['keypoints']);
        if len(keypoints_history) < keypoints_history.maxlen: continue
        velocity = 0
        if keypoints_history[0] is not None and keypoints_history[-1] is not None:
            hip_now, hip_prev = keypoints_history[-1][12], keypoints_history[0][12]
            if not np.isnan(hip_now).any() and not np.isnan(hip_prev).any():
                velocity = np.linalg.norm(hip_now - hip_prev) / (len(keypoints_history)/fps)
        
        frame_idx = data['frame_idx']
        if state == "IDLE":
            if velocity > VEL_START:
                state = "ACTION"; idle_frame_counter = 0
                start_frame_idx = frame_idx - len(keypoints_history) + 1
                action_buffer = [kp for kp in all_frame_keypoints if kp['frame_idx'] >= start_frame_idx]
        elif state == "ACTION":
            action_buffer.append(data)
            if velocity < VEL_END:
                idle_frame_counter += 1
            else:
                idle_frame_counter = 0
            
            if idle_frame_counter >= IDLE_CONFIRMATION_FRAMES:
                state = "IDLE";
                
                action_buffer = action_buffer[:-IDLE_CONFIRMATION_FRAMES]
                if not action_buffer: continue
                
                start_data, end_data = action_buffer[0], action_buffer[-1]
                duration = (end_data['frame_idx'] - start_data['frame_idx']) / fps
                
                
                if duration < MIN_ACTION_DURATION:
                    action_buffer = []; idle_frame_counter = 0
                    continue
                

                arm_angles, knee_angles, hip_positions = [], [], []
                for d in action_buffer:
                    k = d['keypoints']
                    if k is None: continue
                    arm_angles.append(calculate_angle(k[6],k[8],k[10])); knee_angles.append(calculate_angle(k[12],k[14],k[16])); hip_positions.append(k[12])
                
                valid_arm_angles = [a for a in arm_angles if a is not None]
                valid_knee_angles = [a for a in knee_angles if a is not None]
                max_arm_ext = max(valid_arm_angles) if valid_arm_angles else None
                min_knee_bend = min(valid_knee_angles) if valid_knee_angles else None
                
                lunge_speed = np.linalg.norm(hip_positions[-1]-hip_positions[0])/duration if len(hip_positions)>1 and duration>0 else 0
                
                metrics = {"å¼“æ­¥é€Ÿåº¦(åƒç´ /ç§’)":f"{lunge_speed:.1f}", "æœ€å¤§æ‰‹è‡‚ä¼¸å±•(Â°)":f"{max_arm_ext:.1f}" if max_arm_ext else "N/A", "æœ€å°åè†è§’åº¦(Â°)":f"{min_knee_bend:.1f}" if min_knee_bend else "N/A", "åŠ¨ä½œæ—¶é•¿(ç§’)":f"{duration:.2f}"}
                score = calculate_action_score(metrics, w)
                action_type = "ç›´åˆº" if lunge_speed > 60.0 else "æ ¼æŒ¡/ç§»åŠ¨"
                
                action = {"id":f"action_{len(detected_actions)+1}", "type":action_type, "score":score, "timestamp_sec":start_data['frame_idx']/fps, "timestamp_str":time.strftime('%M:%S',time.gmtime(start_data['frame_idx']/fps)), "metrics":metrics}
                detected_actions.append(action); action_buffer = []; idle_frame_counter = 0

    report_highlights = []
    if len(detected_actions) >= 2:
        detected_actions.sort(key=lambda x: x['score'])
        for action, type, desc in [(detected_actions[0], 'bad', 'å¾…æ”¹è¿›'), (detected_actions[-1], 'good', 'äº®ç‚¹')]:
            cap.set(cv2.CAP_PROP_POS_FRAMES, int(action['timestamp_sec'] * fps)); success, frame = cap.read()
            if success:
                results = model(frame.copy(), verbose=False); annotated_frame = results[0].plot()
                image_path = os.path.join(output_dir, f"highlight_{type}.jpg"); cv2.imwrite(image_path, annotated_frame)
                report_highlights.append({"type":type, "timestamp":action['timestamp_str'], "title":f"åŠ¨ä½œ: {action['type']}", "description":f"æœ¬æ¬¡åˆ†æä¸­çš„ä¸€ä¸ª{desc}æ—¶åˆ»ï¼Œè¯„åˆ†ä¸º {action['score']}ã€‚", "image_path":image_path})
    cap.release()
    
    action_scores = defaultdict(list); action_categories = {"è¿›æ”»":["ç›´åˆº"],"é˜²å®ˆ":["æ ¼æŒ¡/ç§»åŠ¨"]}
    for action in detected_actions:
        for cat, types in action_categories.items():
            if action['type'] in types: action_scores[cat].append(action['score'])
    def get_avg(cat): return sum(action_scores[cat])/len(action_scores[cat])*10 if action_scores[cat] else random.randint(60,70)
    summary_data = {"radar":{"labels":["è¿›æ”»","é˜²å®ˆ","é€Ÿåº¦","å‘½ä¸­ç‡","å˜åŒ–ä¸æˆ˜æœ¯"], "last_training":[random.randint(60,90) for _ in range(5)], "this_training":[get_avg("è¿›æ”»"), get_avg("é˜²å®ˆ"), random.randint(70,95), random.randint(65,90), random.randint(60,85)]}, "line":{"categories":[f"ç¬¬{i+1}è½®" for i in range(10)], "last_day":[random.randint(60,80) for _ in range(10)], "today":[random.randint(65,85) for _ in range(10)]}}
    generate_chart_image('radar', summary_data['radar'], os.path.join(output_dir, 'radar_chart.png'))
    generate_chart_image('line', summary_data['line'], os.path.join(output_dir, 'line_chart.png'))
    report_data = {"date":time.strftime('%Y-%m-%d'), "highlights":report_highlights, "ai_summary":"æœ¬æ¬¡è®­ç»ƒåŸºäºYOLOv8çœŸå®æ•°æ®åˆ†æå®Œæˆã€‚"}
    generate_html_report(report_data, output_dir)
    
    detected_actions.sort(key=lambda x: x['timestamp_sec'])
    return {"analysis_data": {"detected_actions": detected_actions, "summary_data": summary_data}, "report_session_id": session_id}